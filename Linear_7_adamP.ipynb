{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4dbc61-25f7-48d9-9b0f-da703ee43586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/hw\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler  # 이 부분을 추가하세요\n",
    "import neurokit2 as nk \n",
    "from adamp import AdamP\n",
    "import wandb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the path to your tar.gz file\n",
    "os.chdir('/home/ubuntu/hw')\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170d62e7-e0f8-4bb6-8818-e377169ceee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_pqr(signal, sr):\n",
    "    try:\n",
    "        signals = signal.reshape(-1,)\n",
    "        signals = nk.ecg_clean(signals, 250, method='neurokit') #디노이징\n",
    "        _, rpeaks = nk.ecg_peaks(signals, sampling_rate = sr)\n",
    "        _, waves_peak = nk.ecg_delineate(signals, rpeaks, sampling_rate = sr, method='peak')\n",
    "\n",
    "        r_peaks = np.array(rpeaks['ECG_R_Peaks'])\n",
    "        r_peaks = r_peaks[~np.isnan(r_peaks)].astype('int')\n",
    "\n",
    "        p_peaks = np.array(waves_peak['ECG_P_Peaks'])\n",
    "        p_peaks = p_peaks[~np.isnan(p_peaks)].astype('int')\n",
    "\n",
    "        q_peaks = np.array(waves_peak['ECG_Q_Peaks'])\n",
    "        q_peaks = q_peaks[~np.isnan(q_peaks)].astype('int')\n",
    "\n",
    "        s_peaks = np.array(waves_peak['ECG_S_Peaks'])\n",
    "        s_peaks = s_peaks[~np.isnan(s_peaks)].astype('int')\n",
    "\n",
    "        t_peaks = np.array(waves_peak['ECG_T_Peaks'])\n",
    "        t_peaks = t_peaks[~np.isnan(t_peaks)].astype('int')\n",
    "\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.plot(signals)\n",
    "        plt.plot(p_peaks, signals[p_peaks], \"o\", markersize = 6, label = 'P_peaks')\n",
    "        plt.plot(q_peaks, signals[q_peaks], \"o\", markersize = 6, label = 'Q_peaks')\n",
    "        plt.plot(r_peaks, signals[r_peaks], \"o\", markersize = 6, label = 'R_peaks')\n",
    "        plt.plot(s_peaks, signals[s_peaks], \"o\", markersize = 6, label = 'S_peaks')\n",
    "        plt.plot(t_peaks, signals[t_peaks], \"o\", markersize = 6, label = 'T_peaks')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "        # 오류가 발생한 경우 NaN 배열을 반환하여 시각화 부분에서 건너뜁니다.\n",
    "        return np.full_like(signal, np.nan)\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd277812-c83d-491e-9ade-0c0c04583401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3ki6x63n) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>Training Loss</td><td>▁▂▃▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂█▁▁▁▂▁▁▁▂▂▁▂▂▁▁▁▁▂▇▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Training Loss</td><td>0.99459</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sound-8</strong> at: <a href='https://wandb.ai/chwo67/Linear7_AdamP/runs/3ki6x63n' target=\"_blank\">https://wandb.ai/chwo67/Linear7_AdamP/runs/3ki6x63n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231123_175330-3ki6x63n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3ki6x63n). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter-melee/wandb/run-20231124_080009-9j46j3hy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chwo67/Linear7_AdamP/runs/9j46j3hy' target=\"_blank\">grateful-microwave-9</a></strong> to <a href='https://wandb.ai/chwo67/Linear7_AdamP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chwo67/Linear7_AdamP' target=\"_blank\">https://wandb.ai/chwo67/Linear7_AdamP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chwo67/Linear7_AdamP/runs/9j46j3hy' target=\"_blank\">https://wandb.ai/chwo67/Linear7_AdamP/runs/9j46j3hy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2->전체 회귀모델\n",
    "# Drop out 추가 \n",
    "\n",
    "wandb.init(project=\"Linear7_AdamP\")\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리 함수\n",
    "def load_npy_data(folder_path):\n",
    "    X_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith('wave') and file_name.endswith('.npy'):\n",
    "            data = np.load(os.path.join(folder_path, file_name))\n",
    "\n",
    "            if data.shape[0] == 13:\n",
    "                data = data[:12, :]  # 13번째 행 제거\n",
    "                \n",
    "                # 디노이징을 위해 각 리드별로 nk.ecg_clean 적용\n",
    "                cleaned_data = []\n",
    "                for i in range(data.shape[0]):  # 각 리드에 대해 반복\n",
    "                    cleaned = nk.ecg_clean(data[i, :], 250, method='neurokit')\n",
    "                    cleaned_data.append(cleaned)\n",
    "                cleaned_data = np.array(cleaned_data)\n",
    "                X_list.append(cleaned_data)\n",
    "            else:\n",
    "                print(f\"파일 {file_name}의 형식이 올바르지 않습니다: data shape {data.shape}\")\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    return X\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "folder_path = \"diffusion/data_No20000/data_0\"\n",
    "X = load_npy_data(folder_path)\n",
    "\n",
    "# 데이터셋 분할 및 DataLoader 설정\n",
    "dataset_size = len(X)\n",
    "test_size = int(0.2 * dataset_size)\n",
    "train_size = dataset_size - test_size\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.reshape(-1, 5000)).reshape(-1, 12, 5000)\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "# 데이터셋 분할 및 DataLoader 설정\n",
    "dataset = TensorDataset(X_tensor)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "\n",
    "# 선형 회귀 모델 클래스\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2048)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        return self.fc7(x)\n",
    "\n",
    "\n",
    "# 모델 초기화 및 CUDA 설정\n",
    "device = torch.device('cuda:5')\n",
    "input_size = 5000  # Lead II의 데이터 길이\n",
    "output_size = 5000 * 11  # 나머지 11개 리드의 데이터 길이\n",
    "\n",
    "# 모델 초기화\n",
    "lin_reg_model = LinearRegressionModel(input_size, output_size).to(device)\n",
    "\n",
    "# 옵티마이저\n",
    "params = lin_reg_model.parameters()\n",
    "lin_reg_optimizer = AdamP(params, lr=0.001, betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "# 훈련 루프\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:  # 여기를 수정했습니다\n",
    "        data = data[0].to(device)  # data는 튜플이 아니라 바로 텐서입니다\n",
    "        lead_II = data[:, 1, :]  # 두 번째 리드 (Lead II) 선택\n",
    "        remaining_leads = data[:, [i for i in range(12) if i != 1], :].reshape(-1, 5000 * 11)  # 나머지 11개 리드 선택 및 재구성\n",
    "\n",
    "        # 예측 및 손실 계산\n",
    "        lin_reg_optimizer.zero_grad()\n",
    "        predictions = lin_reg_model(lead_II)\n",
    "        loss = nn.MSELoss()(predictions, remaining_leads)\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        lin_reg_optimizer.step()\n",
    "        wandb.log({\"Epoch\": epoch, \"Training Loss\": loss.item()})        \n",
    "    # 10 epoch마다 평균 MSE와 R-squared 점수를 계산하고 wandb에 로깅\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # 테스트 데이터셋에 대한 예측 및 점수 계산\n",
    "        mse_scores, r2_scores = [], []\n",
    "        lin_reg_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                data = data[0].to(device)\n",
    "                lead_II = data[:, 1, :].view(-1, 5000)\n",
    "                remaining_leads = data[:, [i for i in range(12) if i != 1], :].reshape(-1, 55000)\n",
    "                \n",
    "                predictions = lin_reg_model(lead_II)\n",
    "                mse = mean_squared_error(remaining_leads.cpu().numpy(), predictions.cpu().numpy())\n",
    "                r2 = r2_score(remaining_leads.cpu().numpy(), predictions.cpu().numpy())\n",
    "                \n",
    "                mse_scores.append(mse)\n",
    "                r2_scores.append(r2)\n",
    "\n",
    "        # 평균 점수 계산\n",
    "        average_mse = np.mean(mse_scores)\n",
    "        average_r2 = np.mean(r2_scores)\n",
    "\n",
    "        # wandb에 로깅\n",
    "        wandb.log({\"Epoch\": epoch, \"Average MSE\": average_mse, \"Average R-squared\": average_r2})\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# 시각화 함수\n",
    "def plot_ecgs(original, predicted, sample_index):\n",
    "    fig, axes = plt.subplots(12, 2, figsize=(15, 20))\n",
    "    for i in range(12):\n",
    "        if i == 1:  # 2번째 리드(Lead II)는 입력 데이터\n",
    "            axes[i, 0].plot(original[sample_index, i, :])\n",
    "            axes[i, 1].plot(original[sample_index, i, :])\n",
    "        else:\n",
    "            axes[i, 0].plot(original[sample_index, i, :])\n",
    "            axes[i, 1].plot(predicted[sample_index, i - 1 if i > 1 else i, :])\n",
    "        axes[i, 0].set_title(f'Original Lead {i+1}')\n",
    "        axes[i, 1].set_title(f'Predicted Lead {i+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 예측 및 시각화\n",
    "lin_reg_model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_data = next(iter(test_loader))[0]\n",
    "    lead_II = sample_data[:, 1, :].to(device)\n",
    "    predicted = lin_reg_model(lead_II).view(-1, 11, 5000).cpu()\n",
    "    plot_ecgs(sample_data.numpy(), predicted, 0)  # 첫 번째 샘플에 대한 시각화\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def calculate_scores(original, predicted):\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    # 각 리드에 대한 MSE 및 R-squared 점수 계산\n",
    "    for i in range(12):\n",
    "        if i != 1:  # 2번째 리드(Lead II)는 입력 데이터이므로 제외\n",
    "            original_lead = original[:, i, :]\n",
    "            predicted_lead = predicted[:, i - 1 if i > 1 else i, :]\n",
    "            mse = mean_squared_error(original_lead, predicted_lead)\n",
    "            r2 = r2_score(original_lead, predicted_lead)\n",
    "            mse_scores.append(mse)\n",
    "            r2_scores.append(r2)\n",
    "    \n",
    "    return mse_scores, r2_scores\n",
    "\n",
    "# 테스트 데이터셋에 대한 예측 및 점수 계산\n",
    "lin_reg_model.eval()\n",
    "total_mse = []\n",
    "total_r2 = []\n",
    "with torch.no_grad():\n",
    "    for sample_data in test_loader:\n",
    "        data = sample_data[0].to(device)\n",
    "        lead_II = data[:, 1, :]\n",
    "\n",
    "        predicted_output = lin_reg_model(lead_II)\n",
    "        if predicted_output.shape[1] == 55000:  # 출력 크기가 55000일 때만 재구성\n",
    "            predicted = predicted_output.view(-1, 11, 5000).cpu()\n",
    "            mse_scores, r2_scores = calculate_scores(data.cpu().numpy(), predicted.numpy())\n",
    "            total_mse.extend(mse_scores)\n",
    "            total_r2.extend(r2_scores)\n",
    "        else:\n",
    "            print(\"Invalid model output size\")\n",
    "\n",
    "wandb.log({\"Average MSE\": np.mean(total_mse)})\n",
    "wandb.log({\"Average R-squared\": np.mean(total_r2)}) \n",
    "\n",
    "# 평균 MSE 및 R-squared 점수 출력\n",
    "print(f'Average MSE: {np.mean(total_mse)}')\n",
    "print(f'Average R-squared: {np.mean(total_r2)}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt20_py310",
   "language": "python",
   "name": "pt20_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
